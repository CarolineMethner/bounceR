% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/featureSelection.R
\name{featureSelection}
\alias{featureSelection}
\title{Automated Feature Selection for Machine Learning Models with Boosting Ensembles}
\usage{
featureSelection(data, target, index = NULL, selection = selectionControl(),
  bootstrap = "none", boosting = boostingControl(),
  early_stopping = "none", n_cores = 1, verbose = TRUE)
}
\arguments{
\item{data}{a dataset containing the target, all features, and potentially a time index}

\item{target}{a string with the column name of the target}

\item{index}{a string with the column name of the index}

\item{selection}{takes the return from \code{\link{selectionControl}}}

\item{bootstrap}{a string specifying the bootstrap method}

\item{boosting}{takes the return form \code{\link{boostingControl}}}

\item{early_stopping}{a string giving the method for early stopping}

\item{n_cores}{an integer giving the amount of cores}

\item{verbose}{a logical indicating whether logging info is displayed}
}
\value{
a list with the following entries
\itemize{
\item \code{stability} - a stability matrix with two columns: feature names and selection stability score
\item \code{opt_formula} - statistically optimal formula derived from breakpoints in the stability score series
\item \code{setup} - a list with misc. configurations
}
}
\description{
Automated Feature Selection for Machine Learning Models with Boosting Ensembles
}
\details{
This function implements a feature selection algorithm leveraging the ideas from backpropagation and randomness. Each n_rounds round a new random 
stability matrix with two columns is initialized. The first column has the name of the feature and the second a stability score indicating the empirical
relevance score of a feature. Each of these n_rounds random matrices is then updated over the course of n_mods componentwise boosting models on 
random subsets of the feature space. The updating process works as follows: if a feature was contained in a subset, but was not selected in the boosting,
it's score in the randomly intialized matrix is reduced by the amount of the penalty. If a feature was contained in a subset and was selected in a boosting, 
it's score in the randomly intialized matrix is increased by the amount of the reward. After n_mods models in each n_rounds rounds the n_rounds updated 
stability matrices are combined by simply averaging the scores for each feature across all matrices.
}
\examples{
\dontrun{
# Simulate Data
test_df <- sim_data()

# Genetic Boosting Ensemble
test_ge <- featureSelection(data = test_df,
                            target = "y",
                            selection = selectionControl(n_rounds = 10,
                                                         n_mods = 100,
                                                         p = 30,
                                                         penalty = 0.3,
                                                         reward = 0.2),
                            bootstrap = "regular",
                            early_stopping = "none",
                            n_cores = 1)
}
}
